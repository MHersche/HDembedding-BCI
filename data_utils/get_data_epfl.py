#!/usr/bin/env python3

'''	Loads the EPFL data set
available on http://bnci-horizon-2020.eu/database/data-sets
'''


import sys, os,glob
from filters import butter_bandpass_filter
import numpy as np
import scipy.io as sio


__author__ = "Michael Hersche"
__email__ = "herschmi@ethz.ch,tinor@ethz.ch"

N_CHANNELS = 16

offline_subject_folder = {1:'Offline/q1_20140311/',  2:'Offline/r8_20140818/',3:'Offline/s5_20140905/',4:'Offline/x3_20150505/',5:'Offline/u9_20150305/',6:'Offline/q5_20140520/'}


TRIALS_SESSION = 45 # number of trials per session
#Codes used in EEG recording protocol
START_CODE = 781 
LEFT_CODE = 769
RIGHT_CODE = 770
FEET_CODE = 771
REST_CODE = 783
FIXC_CODE = 786

CORRECT_COMM = 897
WRONG_COMM = 898

# Frequency of sampling
FS = 512
# Duration of each task in second
TASK_DURATION = 4 #[sec]
# Number of samples in a mental command
N_SAMPLES = TASK_DURATION * FS 

def get_data_epfl(data_path,subject,fold = 0,online=False,do_print= False):
	'''	Loads the dataset generated by EPFL 

	Keyword arguments:
	subject -- number of subject in [1, .. ,7]
	7 : online dataset 
	
	Return:	data_return 	numpy matrix 	size = NO_valid_trial x 16 x 4*FS
			class_return 	numpy matrix 	size = NO_valid_trial
	'''

	# Online dataset 
	if online: 
		test_file_list = glob.glob(data_path + online_subject_folder[subject]+"*mi_rhlh.mat")
		test_file_list = [test_file_list[fold]]
		train_file_list = glob.glob(data_path + online_subject_folder[subject]+"*rhlh_20140313.mat")
	# Offline dataset
	else: 
		# Divide files into test files and train files 
		train_file_list = glob.glob(data_path + offline_subject_folder[subject]+"*.mat")
		n_files = len(train_file_list)
		test_file_list = [train_file_list[fold%n_files]]	
		train_file_list.remove(test_file_list[0]) # remove test file from train file list 
	
	train_data,train_label = get_decoded_data(train_file_list)
	test_data,test_label = get_decoded_data(test_file_list)

	if do_print: 
		print("Loaded EPFL dataset in cross validation")
		print('Fold :{}/{} \nNumber of training trials: {} \nNumber of test trials: {}'.format(fold,len(train_file_list),len(train_label),len(test_label)))


	return train_data,train_label,test_data,test_label




def get_decoded_data(file_list,class_vec = [1,2,3]):
	"""
	Load signals and label from file_list 

	Parameters
	----------
	file_list: list of strings, shape (n_files)
		input file list 
	
	Return
	------
	out_data : array, shape (n_trial,N_CHANNELS, N_SAMPLES)
		output data stacked to trials 
	"""

	n_trial = TRIALS_SESSION*len(file_list) # 
	out_label = np.zeros(n_trial,dtype = int)
	out_data = np.zeros((n_trial, N_CHANNELS,N_SAMPLES)) 
	
	out_idx = 0
	for file in file_list: 
		
		# loat data 
		data = sio.loadmat(file)
		Trigger = data['Trigger']
		Position = data['Position']
		# remove mean from signal 
		signal = data['signal'] - np.mean(data['signal'])
		# laplacian filter (Spatial)
		#signal = np.matmul(signal,lap_filt)
		# bandpass filtering 
		signal = butter_bandpass_filter(signal, lowcut=0.1, highcut=100, fs=512, order=4)

		for idx in range(len(Trigger)): 
			if  Trigger[idx] == FIXC_CODE:
				fixation_start = Position[idx]
			elif Trigger[idx] == LEFT_CODE:
				label = 1;
				fixation_end = Position[idx]
			elif Trigger[idx] == RIGHT_CODE:
				label = 2;
				fixation_end = Position[idx]
			elif Trigger[idx] == FEET_CODE:
				label = 3;
				fixation_end = Position[idx]
			elif Trigger[idx] == REST_CODE:
				label = 0;
			elif Trigger[idx] == START_CODE:
				if label in class_vec: 

					# task starts with START_CODE and lasts for 4 sec 
					task_start = int(Position[idx])
					task_end = task_start + N_SAMPLES
					out_data[out_idx] = signal[task_start:task_end].transpose()
					out_label[out_idx]= label 
					out_idx +=1 

	return out_data[:out_idx],out_label[:out_idx]






